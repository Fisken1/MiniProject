{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "CNN for X-ray images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#Paths to the data used in the project\n",
    "train_path = 'chest_xray/train'  #Train set\n",
    "test_path = 'chest_xray/test'  #Test set\n",
    "valid_path = 'chest_xray/val'  #Validation set\n",
    "#The dimension of the images we are going to define is 500x500\n",
    "img_height = 500\n",
    "img_width = 500"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def preprocessing(batch_size):\n",
    "    #Data augmentation used to artificially incraese the size of image training dataset. This will improve the models ability to predict new images\n",
    "\n",
    "    #The image data generator for the training set\n",
    "    image_gen = ImageDataGenerator(\n",
    "        rescale=1. / 255,  #make the image contribute equally\n",
    "        shear_range=0.2,  #streatces the image at a certain angle\n",
    "        zoom_range=0.2,  #The image is enlarged\n",
    "        horizontal_flip=True,  #Randomly flip some images horizontaly\n",
    "    )\n",
    "\n",
    "    #The image data generator for the test and validation sets\n",
    "    test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    #Load the images\n",
    "    train = image_gen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(img_height, img_width),\n",
    "        color_mode='grayscale',\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    valid = test_data_gen.flow_from_directory(\n",
    "        valid_path,\n",
    "        target_size=(img_height, img_width),\n",
    "        color_mode='grayscale',\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test = test_data_gen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(img_height, img_width),\n",
    "        color_mode='grayscale', shuffle=False,  #Shuffle here is false to prevent indexing complications\n",
    "        class_mode='binary',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(train.classes),\n",
    "        y=train.classes\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    return train, valid, weights, test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(128, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(activation='relu', units=256))\n",
    "cnn.add(Dense(activation='relu', units=128))\n",
    "cnn.add(Dense(activation='sigmoid', units=1))\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 498, 498, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 249, 249, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 247, 247, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 123, 123, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 121, 121, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 60, 60, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 58, 58, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 29, 29, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 215296)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               55116032  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,536,897\n",
      "Trainable params: 55,536,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "callbacks_list = [early, learning_rate_reduction]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def run(batch_size, epochs, runs):\n",
    "    current_run = 0\n",
    "\n",
    "    train, valid, weights, test = preprocessing(batch_size)\n",
    "\n",
    "    cw = dict(zip(np.unique(train.classes), weights))\n",
    "\n",
    "    while current_run < runs:\n",
    "        print(\"Run:\", current_run)\n",
    "        cnn.fit(train, epochs=epochs, validation_data=valid, class_weight=cw, callbacks=callbacks_list)\n",
    "        current_run += 1\n",
    "\n",
    "    test_accu = cnn.evaluate(test)\n",
    "    print('The testing accuracy is :', test_accu[1] * 100, '%')\n",
    "\n",
    "    preds = cnn.predict(test, verbose=1)\n",
    "    predictions = preds.copy()\n",
    "    predictions[predictions <= 0.5] = 0 #Normal case\n",
    "    predictions[predictions > 0.5] = 1  #Pneumonia case\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "    cm = pd.DataFrame(data=confusion_matrix(test.classes, predictions, labels=[0, 1]),\n",
    "                      index=[\"Actual Normal\", \"Actual Pneumonia\"],\n",
    "                      columns=[\"Predicted Normal\", \"Predicted Pneumonia\"])\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    print(classification_report(y_true=test.classes, y_pred=predictions, target_names=['NORMAL', 'PNEUMONIA']))\n",
    "\n",
    "    test.reset()\n",
    "    x = np.concatenate([test.next()[0] for i in range(test.__len__())])\n",
    "    y = np.concatenate([test.next()[1] for i in range(test.__len__())])\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    #this little code above extracts the images from test Data iterator without shuffling the sequence\n",
    "    # x contains image array and y has labels\n",
    "    dic = {0: 'NORMAL', 1: 'PNEUMONIA'}\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(228, 9 + 228):\n",
    "        if preds[i, 0] >= 0.5: #if Pneumonia:\n",
    "            out = ('{:.2%} probability of being Pneumonia case'.format(preds[i][0]))\n",
    "            plt.title(out + \"\\n Actual case : \" + dic.get(y[i]))\n",
    "            plt.imshow(np.squeeze(x[i]))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            out = ('{:.2%} probability of being Normal case'.format(1 - preds[i][0]))\n",
    "            plt.title(out + \"\\n Actual case : \" + dic.get(y[i]))\n",
    "            plt.imshow(np.squeeze(x[i]))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    pd.DataFrame(cnn.history.history).plot()  #NEVER HAPPENS PLEASE TAKE A LOOK AT IT!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Run: 0\n",
      " 15/326 [>.............................] - ETA: 12:38 - loss: 0.5960 - accuracy: 0.7167"
     ]
    }
   ],
   "source": [
    "run(16, 1, 1)  #Batch size = 16 , Epochs = 1, runs = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
